# PrimordiumEvolv Minimal (Self-Evolving Engine)
Local UI, tools, evolution loop, and **self-evolving meta-system** calling a local Ollama model with validation, rate limiting, semantic scoring, persistent memory, and intelligent prompt optimization.

## Prereqs
- Python 3.11+
- Ollama running with the model pulled:
  - `ollama pull qwen3:4b` (or set MODEL_ID to your local tag)
  - `ollama serve`

## Setup
```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
cp .env.example .env
make ingest   # optional: index files in ./data
make run      # http://localhost:8000
```

## Features
- Chat + Stream Chat: With session memory; optional live token streaming.
- Memory: FAISS vector search over conversations (cached in‚Äëprocess for speed).
- Meta‚ÄëEvolution: UCB1 bandit with advanced total_reward system (outcome + process - cost) featuring two-judge AI evaluation with tie-breaker over operators (system, nudge, temp, memory, RAG, web). All generation uses local Ollama.
- Recipes + Analytics: Persists best recipes; operator stats tracked over time with reward breakdown.
- RAG: Local vector search (FAISS + sentence‚Äëtransformers) over files in `data/`.
- Web Search: Tavily (if key) with DDG fallback.
- **Advanced AI Scoring**: Two-judge evaluation system with Groq models for assessment only (not generation), automatic tie-breaker for disagreements, and hybrid AI/semantic scoring for robust quality assessment.
- **Human-in-the-Loop Rating**: Direct human feedback integration with 1-10 scale modifying AI response scores (penalties for 1-4, neutral at 5, boosts for 6-10).
- Realtime: Async runs + SSE live updates; inspect full variant output.
- Adaptive Chat: Simple thumbs‚Äëbased learning for temperature (opt‚Äëin via buttons).
- Hardened: GZip, structured errors, rate‚Äëlimit exemptions for streams.

## Advanced AI Scoring System

The system features a sophisticated **evaluation-only** system for robust quality assessment. **All text generation uses local Ollama models** - Groq is used exclusively for judging response quality.

### **Two-Judge + Tie-Breaker Architecture**
- **Local Generation**: All AI responses generated by local Ollama models
- **Remote Evaluation**: Two different Groq models independently score each Ollama-generated response
- **Disagreement Detection**: If judges differ by ‚â•0.3 points, automatic tie-breaker is triggered
- **Final Decision**: Third Groq judge reviews both evaluations and makes definitive judgment

### **Model Pool & Rotation**
Ten cutting-edge models with intelligent rotation for fair distribution:
- `llama-3.3-70b-versatile` - Advanced reasoning capabilities
- `openai/gpt-oss-120b` - Large-scale language understanding  
- `openai/gpt-oss-20b` - Efficient high-quality evaluation
- `llama-3.1-8b-instant` - Fast, reliable scoring
- `groq/compound` - Multi-faceted analysis
- `groq/compound-mini` - Lightweight evaluation
- `meta-llama/llama-4-maverick-17b-128e-instruct` - Latest instruction-following
- `meta-llama/llama-4-scout-17b-16e-instruct` - Exploration-focused evaluation
- `qwen/qwen3-32b` - Advanced multilingual capabilities
- `moonshotai/kimi-k2-instruct` - Specialized instruction understanding

### **Scoring Methodology**
- **90% AI Judgment**: Evaluates correctness, completeness, clarity, relevance, usefulness
- **10% Semantic Similarity**: Ensures topical alignment with task requirements
- **Robust Fallbacks**: Graceful degradation if AI models unavailable

## System Voices for Generation

Eight distinct system prompts (‚Äúvoices‚Äù) are available for generation; selection is task‚Äëaware and optimized by learning. Enable with `FF_SYSTEMS_V2=1`.

- Engineer (precise executor): ‚ÄúYou are a concise senior engineer. Return minimal, directly usable code or config.‚Äù
- Analyst (constraint checker): ‚ÄúYou are a careful analyst. Trace reasoning in brief steps and confirm assumptions are valid.‚Äù
- Optimizer (tradeoff explorer): ‚ÄúYou are a creative optimizer. Generate alternatives, compare tradeoffs, and justify the best option.‚Äù
- Specialist (accuracy enforcer): ‚ÄúYou are a detail-oriented specialist. Ensure correctness, compliance, and complete coverage of edge cases.‚Äù
- Architect (systems thinker): ‚ÄúYou are an experienced architect. Design robust, extensible systems with long-term maintainability.‚Äù
- Product Strategist: ‚ÄúYou are a pragmatic product strategist. Frame solutions in terms of user value, business impact, and constraints.‚Äù
- Experimenter: ‚ÄúYou are a rapid prototyper. Propose small, low-risk tests to validate ideas quickly.‚Äù
- Skeptic: ‚ÄúYou are a rigorous skeptic. Stress-test assumptions and highlight potential failures.‚Äù

Analytics expose voice usage and mean total_reward/cost per system string.
## Groq Integration (Evaluation Only)
- Set `GROQ_API_KEY` in `.env` for AI-powered response evaluation.
- Verify with `GET /api/health/groq`.
- **Generation**: Always uses local Ollama models
- **Evaluation**: Uses Groq models for two-judge scoring system with tie-breaker
- Groq is never used for text generation - only for quality assessment of Ollama-generated responses

## Real-time Meta Runs
- Async start: `POST /api/meta/run_async` returns `{ run_id }` immediately and performs the run in the background.
- Live updates (SSE): `GET /api/meta/stream?run_id=<id>` streams staged iteration lifecycle events so progress is visible at each step.
- UI shows per-iteration status, judges, and a heartbeat (elapsed timer + spinner), plus a rating panel when a variant is saved.

### Staged Iteration Events (SSE)
For each iteration `i`, the server publishes these event types:

- `iter_selected`: `{ i, operator, engine, timestamp }`
- `iter_gen_start`: `{ i, prompt_length, timestamp }`
- `iter_gen_done`: `{ i, duration_ms, prompt_length, timestamp }`
- `iter_score_done`: `{ i, total_reward, reward_breakdown:{outcome,process,cost}, judge_info:{judges:[{model,score}], tie_breaker_used, final_score}, timestamp }`
- `iter_saved`: `{ i, variant_id, timestamp }`
- `iter_error`: `{ i, message, timestamp }`
- `iter` (legacy/compat): includes `output` and `variant_id` for rating UI, plus summary fields
- `judge`: high-level judge report (pairwise mode)
- `done`: final results (sanitized to remove NaN/¬±Infinity)

Notes:
- Staged publishing keeps the UI active even if later steps fail (e.g., DB write), avoiding the ‚Äúfrozen until done‚Äù effect.
- The final payload is sanitized to avoid JSON.parse issues in browsers.

## Generation & Evaluation Policy

- All generation is local via Ollama. The engine is enforced as `engine="ollama"` for meta-evolution.
- Groq is used strictly in the evaluation layer (two-judge + optional tie-breaker) to score outputs.
- Artifacts include judge metadata (per-judge scores, model ids, timing) under the evaluation block.

## M1 Upgrades (Enabled by Default)
- **UCB1 Bandit Algorithm**: Default strategy with warm start and stratified exploration for optimal operator diversity.
- **Advanced Total Reward System**: Three-component reward with sophisticated outcome evaluation:
  - **Outcome Reward**: Two-judge AI evaluation (90%) + semantic similarity (10%) with automatic tie-breaker
  - **Process Reward**: Structured reasoning, code quality, and methodology assessment  
  - **Cost Penalty**: Resource efficiency (time, tokens, tool calls) vs baseline
  - **Promotion Policy**: Œî ‚â• 0.05, cost ‚â§ 0.9√óbaseline with detailed AI judgment metadata
- **Enhanced Artifacts**: Each run generates `reward_breakdown` with detailed judge evaluations and `bandit_state` snapshots for full transparency.
- Trajectory Logging: Writes `runs/{timestamp}/trajectory.json` with per‚Äëiteration operator, engine, time, score, and total_reward.
- Operator Masks per Task: Optional masks from `storage/operator_masks.json` (keys are task_class), supporting `framework_mask` (e.g., `["SEAL","ENGINE"]`) and `operators` allowlists.
- Eval Suite + Gating: Safety probes run at end of run and write `runs/{timestamp}/eval_report.json`. Results include promotion criteria analysis.
- **Bandit Configuration**: UCB exploration constant `c=2.0`, warm start `min_pulls=1`, stratified exploration enabled.
- Defaults: Meta `n=16` with UCB strategy (override via `BANDIT_STRATEGY`, `UCB_C`, `WARM_START_MIN_PULLS`).

Feature Flags (in `.env`)
- `FF_TRAJECTORY_LOG=1`, `FF_PROCESS_COST_REWARD=1`, `FF_OPERATOR_MASKS=1`, `FF_EVAL_GATE=1` (all ON by default).
- UCB Configuration: `BANDIT_STRATEGY=ucb`, `UCB_C=2.0`, `WARM_START_MIN_PULLS=1`, `STRATIFIED_EXPLORE=true`.
- Reward weights: `REWARD_ALPHA=1.0`, `REWARD_BETA_PROCESS=0.2`, `REWARD_GAMMA_COST=-0.0005`.

## Judge Mode
- Enable "Judge with Groq" in the Meta panel to pairwise-judge the best local variant against a Groq challenger.
- Responses include a `judge` block; the UI also displays a subtle toast and a verdict panel.

## New Human-Centered UI (v2.0)

The interface has been completely redesigned with human-centered design principles:

### üéØ **Main Evolution Interface**
- **Primary Focus**: Single "üöÄ Start Evolution" button with clear call-to-action
- **Natural Language**: "What should the AI get better at?" instead of technical jargon
- **Task-Oriented**: Dropdown for task types (Code, Analysis, Writing, Business, etc.)
- **Progressive Disclosure**: Advanced settings collapsed by default

### üìä **Real-time Progress**
- **Visual Progress Bar**: Shows evolution completion percentage
- **Live Step Tracking**: "üîÑ Iteration 2: Trying toggle_web" with status updates
- **Streaming Output**: Real-time display of current AI output
- **Heartbeat**: Elapsed time ticker and subtle spinner so it never looks frozen
- **Results Display**: Clear score improvements and strategy summaries

### üé® **Collapsible Sections**
- **üí¨ Quick Test**: Test current AI with immediate responses
- **‚öôÔ∏è Advanced Settings**: Learning rate, memory context, web research controls
- **üìä Evolution History**: View past runs and performance metrics

### üîß **Technical Improvements**
- **Health Monitoring**: Auto-updating Ollama/Groq status badges
- **Debug Logging**: Comprehensive console logging for troubleshooting
- **Error Handling**: Clear error messages with recovery suggestions
- **Mobile-Friendly**: Responsive design for all screen sizes

### üöÄ **Usage Flow**
1. Enter task description (e.g., "Write Python functions with error handling")
2. Select task type and iterations (2-15)
3. Click "üöÄ Start Evolution" 
4. Watch real-time progress with step-by-step updates
5. View results with improvement metrics and best strategies

## UI Tips (Legacy)
- Health badges show Ollama and Groq status in real-time
- Open browser dev tools (F12) to see detailed console logs
- All complex controls are hidden in collapsible sections
- Evolution progress shows live streaming updates

## Judge Mode + Groq
- Set `GROQ_API_KEY` in `.env` (leave `GROQ_MODEL_ID` blank to auto-select from `/models`).
- From the UI, click "List Groq Models" to verify availability.
- Check "Judge with Groq" to enable pairwise judging; responses include a `judge` field like:
  `{"judge":{"mode":"pairwise_groq","verdict":{"winner":"A|B|tie","rationale":"..."},"challenger_model":"groq:model"}}`
- Judge does not alter `best_score`; it provides an orthogonal verdict for audit.

## API Endpoints

### Core
- `GET /` - UI interface
- `GET /api/health` - Health check
- `POST /api/chat` - Chat with model (requires session_id)
- `GET /api/chat/stream` - Stream Chat (SSE)
- `POST /api/chat/feedback` - Thumbs feedback to adapt chat temperature
- `POST /api/evolve` - Run evolution loop

### Session Management
- `POST /api/session/create` - Create new chat session
- `GET /api/session/list` - List all sessions
- `GET /api/session/{id}/messages` - Get messages from session
- `POST /api/session/{id}/append` - Add message to session

### Memory System
- `POST /api/memory/build` - Build vector index from all messages
- `POST /api/memory/query` - Query conversation history semantically
- `GET /api/meta/analytics/memory` - Memory system analytics and metrics

### Meta-Evolution System
- `POST /api/meta/run` - Trigger self-evolution cycle with bandit optimization
- `POST /api/meta/run_async` - Start run in background (returns `run_id`)
- `GET /api/meta/stream?run_id=ID` - Live SSE updates (staged: iter_selected/gen_start/gen_done/score_done/saved/error + judge/done)
- `GET /api/meta/runs/{run_id}` - Run details + variants
- `GET /api/meta/variants/{variant_id}` - Full output for a specific variant

### Human-in-the-Loop Rating

The system integrates direct human feedback to influence AI response quality scoring:

**Rating Scale & Impact:**
- **1-4**: Negative modifiers (penalties) - 1‚Üí0.2x, 4‚Üí0.8x
- **5**: Neutral (1.0x) - no change to score
- **6-10**: Positive modifiers (boosts) - 6‚Üí1.2x, 10‚Üí2.0x

**How It Works:**
1. UI shows rating panel during evolution iterations
2. Human rates response quality on 1-10 scale via UI
3. Rating is stored in `human_ratings` table linked to `variant_id`
4. **Next time that variant is evaluated**, the human rating directly modifies the outcome score
5. Modified score affects operator learning and recipe promotion

**API Integration:**
- `POST /api/meta/rate`
  - Request: `{ "variant_id": number, "human_score": number (1-10), "feedback": string? }`
  - Behavior: Stores rating in database, applied during next evaluation
- `GET /api/meta/variants/{variant_id}` - Fetch full response text for review

**Configuration:**
- `ratings_mode`: `off | prompted` (default `prompted`) - Hide/show rating UI
- `reading_delay_ms`: 0‚Äì8000ms (default 2000ms) - Delay before showing rating panel
- Preferences are stored in browser localStorage and recorded in run metadata.

### Tools
- `POST /api/web/search` - Web search
- `POST /api/rag/build` - Build vector index
- `POST /api/rag/query` - Query vector index

## Quick Test

Test the new memory features:

```bash
# Create a session
curl -X POST http://localhost:8000/api/session/create \
  -H "Content-Type: application/json" \
  -d '{"title": "Test Session"}'
# Returns: {"id": 1}

# Add some messages to the session
curl -X POST http://localhost:8000/api/session/1/append \
  -H "Content-Type: application/json" \
  -d '{"role": "user", "content": "I love programming in Python"}'

curl -X POST http://localhost:8000/api/session/1/append \
  -H "Content-Type: application/json" \
  -d '{"role": "assistant", "content": "Python is great for data science and web development!"}'

# Build the memory index
curl -X POST http://localhost:8000/api/memory/build

# Query the memory
curl -X POST http://localhost:8000/api/memory/query \
  -H "Content-Type: application/json" \
  -d '{"q": "programming languages", "k": 5}'

# Chat with memory context
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"prompt": "What did we discuss about Python?", "session_id": 1}'

# Stream chat tokens (SSE)
# Frontend parses `data: {"token": "..."}` chunks and stops on `{ "done": true }`

## Golden Set

Deterministic micro-benchmarks to validate changes and measure Œî(total_reward) and costs across six task types.

- Storage: `storage/golden/*.json` ‚Äî one item per file with schema:
  `{ id, task_type, task_class, task, assertions[], inputs?, expected?, seed, flags{web, rag_k} }`.
- Task types (coverage ‚â•3‚Äì5 items each): Code & Programming, Data Analysis, Creative Writing, Business Strategy, Research & Facts, General Task.

- Endpoints:
  - `GET /api/golden/list` ‚Äî IDs and metadata.
  - `POST /api/golden/run` ‚Äî runs all or subset, returns KPI JSON.
  - `GET /api/golden/stream` ‚Äî Server‚ÄëSent Events; streams per‚Äëitem progress and final aggregate KPIs.
- Artifacts: `runs/<ts>/golden_kpis.json` with per‚Äëitem and aggregate summary:
  - `per_item`: `{ id, task_type, outcome_reward, process_reward, cost_penalty, total_reward, steps }`
  - `aggregate`: `{ avg_total_reward, avg_cost_penalty, avg_steps, pass_rate }`

## Episodic Memory System ("Memento Memory")

Advanced episodic memory system that learns from past evolution runs to improve future performance through semantic similarity search and evolutionary priming.

### Core Features
- **Pre-run Retrieval**: Searches for similar past cases using HuggingFace embeddings before each evolution run
- **Evolutionary Primer Injection**: Injects relevant past experiences as evolutionary hints into prompts
- **Multi-factor Scoring**: Combines semantic similarity + reward scores + time decay for optimal experience selection
- **Performance Attribution**: Tracks reward lift from memory usage to validate system effectiveness
- **Safety Features**: Pollution guards, LRU eviction, and confidence thresholds prevent memory corruption

### Configuration
Enable with `FF_MEMORY=1` in `.env`. Key settings:
- `MEMORY_K=5` - Number of experiences to retrieve per run
- `MEMORY_REWARD_FLOOR=0.6` - Minimum reward threshold for storing experiences  
- `MEMORY_PRIMER_TOKENS_MAX=800` - Maximum tokens for memory primer injection
- `MEMORY_DECAY_DAYS=30` - Time decay period for experience relevance
- `MEMORY_EMBEDDER=sentence-transformers/all-MiniLM-L6-v2` - HuggingFace embedding model
- `HUGGING_FACE_API_TOKEN=<token>` - Required for embedding API access

### Memory Analytics
The Memory tab in Analytics provides comprehensive insights:
- **Hit Rate**: Percentage of runs that successfully used memory
- **Reward Lift**: Average performance improvement from memory usage  
- **Store Metrics**: Current memory store size and primer token distribution
- **Task Class Breakdown**: Memory performance segmented by task type
- **Recent Runs**: Detailed view of memory usage in recent evolution runs

## Analytics UI (Tabbed)

Open the Analytics panel to explore metrics across eight tabs:

- Overview: KPI tiles (Total Runs, Avg Reward/Score, improvement) + mini trend + task performance.
- Runs: Recent runs list (replaces the old ‚ÄúEvolution History‚Äù panel) with refresh; drill‚Äëdown via `/api/meta/runs/{id}`.
- Operators: Coverage (first K iterations) and operator performance (uses, mean total_reward, avg time).
- Voices: System voice performance (uses, mean total_reward, avg cost_penalty) when enabled.
- Judges: Evaluated count, tie‚Äëbreaker rate, evaluation latency p50/p90.
- Golden: ‚ÄúüèÅ Run Golden Set‚Äù streaming button and per‚Äëtask_type summary; streams via `/api/golden/stream`.
- Costs: Evaluation latency p50/p90 and Golden average cost_penalty.
- Thresholds: Current Phase‚Äë4 thresholds (delta_reward_min, cost_ratio_max, pass_rate_target).
- **Memory**: Hit rates, reward lift, store metrics, and recent memory usage when `FF_MEMORY=1`.

Streaming behavior:
- Evolution runs stream live in the ‚Äúüß¨ Evolution in Progress‚Äù section during a run (`/api/meta/stream`).
- Golden Set streams in the Golden tab while a Golden evaluation is running (`/api/golden/stream`).

## Analytics Reliability

- The `/api/meta/analytics` endpoint always returns a valid JSON shape even if the data store fails; it soft-fails with defaults and `null` values rather than 500.
- Consumers should still check `response.ok` and guard against `null` fields.
- The UI displays a non-blocking message and hides the tiles when analytics can‚Äôt load, so streaming UX is never impacted.

## Phase 4: AlphaEvolve‚Äëlite (Criticize ‚Üí Edit ‚Üí Test ‚Üí Decide)

Safe, automated improvement loop on allowlisted files, gated by the Golden Set and unit tests.

- Enable: set `FF_CODE_LOOP=1` (auto‚Äëinvokes after each meta run completes) or trigger via the existing Phase‚Äë4 endpoint.
- Modes: `CODE_LOOP_MODE=live|dry_run` (default `live`). Dry‚Äërun produces a plan + KPIs without patching.
- Safety: queue + global lock (at‚Äëmost‚Äëone active), idempotency (per `source_run_id`), hard timeout (`CODE_LOOP_TIMEOUT_SECONDS`, default 600s), and rate limit (`CODE_LOOP_MAX_PER_HOUR`, default 3).
- Allowlist + caps: edits limited to reward tuning (via `storage/tuning.json`), `storage/*.json` (Golden Set), and `tests/*`; ‚â§50 LOC per patch, ‚â§3 patches per loop; auto‚Äërevert on failure.
- Acceptance gates (ALL must pass):
  - Unit tests pass (`pytest -q`).
  - `Œî(total_reward)_aggregate ‚â• PHASE4_DELTA_REWARD_MIN` (default 0.05).
  - `avg_cost_penalty_after ‚â§ PHASE4_COST_RATIO_MAX √ó avg_cost_penalty_before` (default 0.9).
  - Artifact schema intact (iteration/trajectory/eval/golden parse and expected fields present).
- Determinism & costs: seeds pinned; `WEB=false`, `rag_k` pinned for Golden runs; model id and RAG index hash logged; evaluation latency is included in `cost_penalty`.
- Artifacts: `runs/<ts>/code_loop.json` with `{ loop_id, source_run_id, mode, critic, patch { unified_diff_snippet, git_commit }, tests, golden_kpis_before_after, thresholds, context, decision }`.

### Configuration (thresholds)

- `PHASE4_DELTA_REWARD_MIN` (float, default `0.05`)
- `PHASE4_COST_RATIO_MAX` (float, default `0.9`)
- `GOLDEN_PASS_RATE_TARGET` (float, default `0.80`)
- `CODE_LOOP_TIMEOUT_SECONDS` (int, default `600`)
- `CODE_LOOP_MAX_PER_HOUR` (int, default `3`)

Thresholds are surfaced in `/api/meta/analytics` and embedded in `code_loop.json`.

## Meta-Evolution System

The self-evolving engine uses UCB1 bandit algorithm with total_reward system to choose optimal prompt mutations:

```bash
# Trigger meta-evolution for code generation
curl -X POST http://localhost:8000/api/meta/run \
  -H "Content-Type: application/json" \
  -d '{
    "session_id": 1,
    "task_class": "code", 
    "task": "Write a Python function to calculate fibonacci numbers",
    "assertions": ["def fibonacci", "recursive"],
    "n": 12,
    "memory_k": 3,
    "rag_k": 3
  }'
```

### Available Operators
All 11 operators systematically explored via UCB1 algorithm with warm start and stratified exploration:

**SEAL Framework (7 operators):**
- `change_system` - Switch system prompt (engineer, analyst, optimizer) 
- `change_nudge` - Modify output format constraints
- `raise_temp/lower_temp` - Adjust creativity vs consistency
- `inject_rag` - Add document context from RAG  
- `inject_memory` - Include conversation history
- `add_fewshot` - Inject domain examples

**WEB Framework (1 operator):**
- `toggle_web` - Enable/disable web search context

**ENGINE Framework (1 operator):**
- `use_groq` - Operator disabled (all generation uses local Ollama)

**SAMPLING Framework (2 operators):**
- `raise_top_k/lower_top_k` - Modify token sampling parameters

**Selection Algorithm (Default: UCB1):**
- `strategy="ucb"` (default) - Upper Confidence Bound with warm start and stratified exploration
- `strategy="epsilon_greedy"` (legacy) - 60% exploration, 40% exploitation

### Generated Artifacts
Each run creates `runs/{timestamp}/`:
- `results.json` - Final metrics with `reward_breakdown` and `bandit_state` snapshots
- `iteration_XX.json` - Per-iteration operator selection with `total_reward` tracking
- `trajectory.json` - Per‚Äëiteration trajectory with reward components (if `FF_TRAJECTORY_LOG=1`)
- `eval_report.json` - Promotion criteria analysis and safety gating (if `FF_EVAL_GATE=1`)
- Recipes automatically saved to database with total_reward-based promotion

### Recipe Evolution
- Successful recipes (Œî(total_reward) ‚â• 0.05 AND cost_penalty ‚â§ 0.9√óbaseline) saved to `recipes` table
- High-performing recipes (Œî(total_reward) ‚â• 0.2 AND cost_penalty ‚â§ 0.8√óbaseline) auto-approved
- Best recipes reused as base for future mutations
- UCB bandit statistics tracked with mean_payoff for optimal operator selection

## Current Results (examples)
- Run 121 (simple_math): best_score=0.260, total_reward=0.798, improvement=+0.798
- Run 120 (other): best_score=0.371, total_reward=0.879, improvement=+0.879  
- Run 119 (research): best_score=0.337, total_reward=0.990, improvement=+0.990

**Current Top Performing Operators:**
- `toggle_web`: n=19, avg_reward=0.703 (web search integration)
- `change_system`: n=16, avg_reward=0.688 (system prompt optimization)
- `lower_top_k`: n=16, avg_reward=0.671 (sampling parameter tuning)
- `change_nudge`: n=17, avg_reward=0.669 (instruction refinement)

**Key Observations:**
- System consistently shows positive improvement from baseline across task types
- Web search (`toggle_web`) remains the highest-performing operator 
- **All generation uses local Ollama** - system optimizes local model performance
- **Human rating integration** provides direct feedback to improve operator learning

## UI Usage (New Evolution Panel)
- Describe task, select Task Type, and click ‚ÄúStart Evolution‚Äù. The run starts via `/api/meta/run_async` and streams progress via SSE.
- ‚ÄúQuick Test‚Äù sends a one‚Äëoff Chat (with memory); ‚ÄúStream Test‚Äù streams the response live.
- Results card shows best score, delta vs baseline, Groq compare, and safety gate status when enabled.

## Troubleshooting
- 500 on `/api/meta/stats`: fixed ‚Äî the endpoint now initializes the meta DB if needed. If you still see errors, ensure the app has write access to `storage/`.
- Empty trajectory/eval: ensure flags are ON in `.env`; artifacts are written only when enabled.
- Long generation: there is no app‚Äëside token cap; generation length is controlled by the local Ollama model. Consider using a smaller/faster local model for quicker iteration.
